# Teste TÃ©cnico: Backend Software Developer

Este projeto foi desenvolvido como parte de um teste tÃ©cnico para implementar uma API HTTP para busca de URLs que contenham um termo fornecido pelo usuÃ¡rio. A aplicaÃ§Ã£o utiliza uma arquitetura hexagonal, permitindo maior testabilidade e manutenibilidade.

---

## ğŸ¯ **Objetivo**

Desenvolver uma aplicaÃ§Ã£o Java para navegar por um website e listar as URLs que contenham um termo fornecido pelo usuÃ¡rio. O sistema suporta mÃºltiplas buscas simultÃ¢neas e retorna resultados parciais enquanto a busca estÃ¡ em andamento.

---

## ğŸš€ **Como executar a aplicaÃ§Ã£o**

### **PrÃ©-requisitos**

- **Docker** instalado na mÃ¡quina
- **VariÃ¡vel de ambiente** `BASE_URL` configurada para determinar a URL base da busca de links.


### **Passos para subir a aplicaÃ§Ã£o**

1. Compile a imagem Docker:

```bash
docker build . -t axreng/backend
```

2. Execute o container Docker:

```bash
docker run -e BASE_URL=http://hiring.axreng.com/ -p 4567:4567 --rm axreng/backend
```


A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel na URL: `http://localhost:4567`.

---

## ğŸ“š **Estrutura do Projeto**

A aplicaÃ§Ã£o segue a arquitetura hexagonal:

```
com.axreng.backend/
â”œâ”€â”€ domain/
â”‚   â”œâ”€â”€ model/             
â”‚   â”‚   â”œâ”€â”€ CrawlJob.java         # Representa as caracterÃ­sticas de uma busca
â”‚   â”‚   â”œâ”€â”€ CrawlStatus.java      # Enum de status ("active" ou "done")
â”‚   â”œâ”€â”€ port/                    
â”‚       â”œâ”€â”€ CrawlerService.java   # Porta para execuÃ§Ã£o de crawling
â”‚       â”œâ”€â”€ CrawlRepository.java  # Porta para persistÃªncia dos jobs
â”œâ”€â”€ application/
â”‚   â”œâ”€â”€ CrawlServiceImpl.java     # Implementa os casos de uso do domÃ­nio
â”œâ”€â”€ adapter/
â”‚   â”œâ”€â”€ in/
â”‚   â”‚   â”œâ”€â”€ web/
â”‚   â”‚   â”‚   â”œâ”€â”€ CrawlController.java # Controla as rotas da API
â”‚   â”‚   â”‚   â”œâ”€â”€ dto/
â”‚   â”‚   â”‚       â”œâ”€â”€ CrawlRequest.java  # RepresentaÃ§Ã£o da requisiÃ§Ã£o POST
â”‚   â”‚   â”‚       â”œâ”€â”€ CrawlResponse.java # RepresentaÃ§Ã£o da resposta GET
â”‚   â”œâ”€â”€ out/
â”‚       â”œâ”€â”€ crawler/
â”‚       â”‚   â”œâ”€â”€ WebCrawlerImpl.java    # ImplementaÃ§Ã£o do mecanismo de busca
â”‚       â”œâ”€â”€ persistence/
â”‚           â”œâ”€â”€ InMemoryCrawlRepository.java # RepositÃ³rio de busca em memÃ³ria
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ SparkConfig.java             # ConfiguraÃ§Ã£o do servidor Spark
â”œâ”€â”€ Main.java                        # Ponto de entrada da aplicaÃ§Ã£o
â””â”€â”€ test/
    â”œâ”€â”€ domain/
    â”‚   â”œâ”€â”€ CrawlJobTest.java        # Testes unitÃ¡rios para o modelo de domÃ­nio
    â”œâ”€â”€ application/
    â”‚   â”œâ”€â”€ CrawlServiceImplTest.java # Testes unitÃ¡rios para os casos de uso
    â”œâ”€â”€ adapter/
    â”‚   â”œâ”€â”€ in/
    â”‚   â”‚   â”œâ”€â”€ web/
    â”‚   â”‚       â”œâ”€â”€ CrawlControllerTest.java # Testes para o controlador da API
    â”‚   â”œâ”€â”€ out/
    â”‚       â”œâ”€â”€ crawler/
    â”‚           â”œâ”€â”€ WebCrawlerImplTest.java # Testes para o mecanismo de busca
```

---

## âœ¨ **Principais Funcionalidades**

1. **POST `/crawl`**:
    - Inicia uma nova busca com o termo fornecido.
    - **RequisiÃ§Ã£o**:

```json
{
  "keyword": "security"
}
```

    - **Resposta**:

```json
{
  "id": "abc12345"
}
```

2. **GET `/crawl/:id`**:
    - Retorna o status da busca e as URLs encontradas atÃ© o momento.
    - **Resposta**:

```json
{
  "id": "abc12345",
  "status": "active",
  "urls": [
    "http://hiring.axreng.com/index2.html",
    "http://hiring.axreng.com/htmlman1/chcon.1.html"
  ]
}
```

3. Suporte a **mÃºltiplas buscas simultÃ¢neas**.
4. Retorno de **resultados parciais** durante a execuÃ§Ã£o da busca.
5. **ExecuÃ§Ã£o paralela** controlada por variÃ¡vel de ambiente (`MULTITHREAD_OPT`).

---

## ğŸ”§ **Tecnologias Utilizadas**

- **Java 11**: Linguagem principal para implementaÃ§Ã£o.
- **Maven**: Gerenciador de dependÃªncias e build.
- **Spark Java**: Framework para a API HTTP.
- **Gson**: Biblioteca para serializaÃ§Ã£o/deserializaÃ§Ã£o JSON.
- **JUnit 5**: Framework para testes unitÃ¡rios.
- **Mockito**: Mocking para simular dependÃªncias nos testes.

---

## âš™ï¸ **VariÃ¡veis de Ambiente**

- `BASE_URL`: Define a URL base onde as buscas serÃ£o feitas.
    - Valor padrÃ£o: `http://hiring.axreng.com/`
- `MULTITHREAD_OPT`: Define se a busca serÃ¡ feita em paralelo.
    - Valores aceitos: `"true"` ou `"false"`
    - Valor padrÃ£o: `"false"`

---

## âœ… **Testes Implementados**

Os testes cobrem todas as camadas da aplicaÃ§Ã£o:

1. **DomÃ­nio (`CrawlJobTest`)**:
    - ValidaÃ§Ã£o da criaÃ§Ã£o do job e sua manipulaÃ§Ã£o (como adicionar URLs encontradas).
2. **AplicaÃ§Ã£o (`CrawlServiceImplTest`)**:
    - Testa os casos de uso para iniciar buscas e consultar jobs existentes.
3. **Adaptadores de Entrada (API, `CrawlControllerTest`)**:
    - Verifica o comportamento esperado dos endpoints POST `/crawl` e GET `/crawl/:id`.
4. **Adaptadores de SaÃ­da (`InMemoryCrawlRepositoryTest`)**:
    - Valida o repositÃ³rio em memÃ³ria, garantindo persistÃªncia correta.
5. **WebCrawler (`WebCrawlerImplTest`)**:
    - Testa a lÃ³gica de resoluÃ§Ã£o de URLs e extraÃ§Ã£o de links.

---

## ğŸ“Š **Avaliando o Desempenho**

- Busca paralela otimizada com `ExecutorService`.
- URLs visitadas sÃ£o armazenadas em uma estrutura thread-safe (`ConcurrentHashMap` ou `synchronizedSet`).
- Limite de 100 resultados por busca, conforme especificado no teste.

---

## ğŸ“ **ObservaÃ§Ãµes**

1. Os arquivos `pom.xml` e `Dockerfile` **nÃ£o foram modificados**, conforme solicitado no teste tÃ©cnico.
2. A aplicaÃ§Ã£o atende a todos os requisitos funcionais descritos, incluindo:
    - ValidaÃ§Ã£o do `keyword` (mÃ­nimo 4, mÃ¡ximo 32 caracteres).
    - Respeito Ã  URL base, seguindo apenas links do mesmo domÃ­nio.
    - Retorno parcial de resultados pela API enquanto a busca ainda estÃ¡ em andamento.
3. A soluÃ§Ã£o foi orientada para ser testÃ¡vel, escalÃ¡vel e simples de manter.

---

ğŸ’¡ **DÃºvidas ou sugestÃµes?** Sinta-se Ã  vontade para entrar em contato! ğŸ˜Š

---

Salve este conteÃºdo como um arquivo `.md` e serÃ¡ renderizado corretamente com qualquer visualizador Markdown. Caso precise de mais ajustes, Ã© sÃ³ avisar! ğŸ˜Š

<div>â‚</div>

[^1]: https://pplx-res.cloudinary.com/image/upload/v1743978412/user_uploads/IvWPLwtDoccAUPR/image.jpg

